# scraper.py
import requests
from bs4 import BeautifulSoup
import time
import logging
from config import HEADERS, TIMEOUT, MAX_RETRIES, RETRY_DELAY


class WuzzufAdvancedScraper:
    def get_soup(self, url):
        """Ø¬Ù„Ø¨ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø© Ù…Ø¹ Ù†Ø¸Ø§Ù… Ø¥Ø¹Ø§Ø¯Ø© Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙŠ Ø­Ø§Ù„ Ø§Ù„Ù€ Timeout"""
        for attempt in range(1, MAX_RETRIES + 1):
            try:
                response = requests.get(url, headers=HEADERS, timeout=TIMEOUT)
                if response.status_code == 200:
                    return BeautifulSoup(response.content, 'lxml')
                logging.warning(f"âš ï¸ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt}: ÙƒÙˆØ¯ Ø§Ù„Ø­Ø§Ù„Ø© {response.status_code}")
            except requests.exceptions.RequestException as e:
                logging.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© {attempt}: {e}")

            time.sleep(RETRY_DELAY)
        return None

    def scrape_page_data(self, page_url):
        """Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¬Ø¯ÙŠØ¯: Ø§Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª Ø£ÙˆÙ„Ø§Ù‹ Ø«Ù… ÙÙƒÙƒÙ‡Ø§ ÙˆØ§Ø­Ø¯Ø© ØªÙ„Ùˆ Ø§Ù„Ø£Ø®Ø±Ù‰"""
        soup = self.get_soup(page_url)
        if not soup:
            return []

        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙ„ Ø­Ø§ÙˆÙŠØ§Øª Ø§Ù„ÙˆØ¸Ø§Ø¦Ù ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø£ÙˆÙ„Ø§Ù‹
        job_containers = soup.find_all('div', {'class':'css-ghe2tq e1v1l3u10'})
        logging.info(f"âœ… ÙˆØ¬Ø¯Ù†Ø§ {len(job_containers)} Ø­Ø§ÙˆÙŠØ© ÙˆØ¸ÙŠÙØ© ÙÙŠ Ø§Ù„ØµÙØ­Ø©.")

        page_results = []

        # 2. Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„ Ø­Ø§ÙˆÙŠØ© ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡Ø§ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙˆØ±Ø§Ø¨Ø·Ù‡Ø§
        for container in job_containers:
            try:
                # 1. Ø§Ø¨Ø­Ø« Ø¹Ù† ÙˆØ³Ù… h2 Ø£ÙˆÙ„Ø§Ù‹
                h2_tag =container.find('h2', {'class': 'css-193uk2c'})

                # 2. Ø§Ø¨Ø­Ø« Ø¹Ù† ÙˆØ³Ù… a Ø¯Ø§Ø®Ù„ h2 ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù†Øµ Ù…Ù†Ù‡
                if h2_tag and h2_tag.a:
                    title = h2_tag.find('a').get_text(strip=True)
                else:
                    title = "N/A"

                if h2_tag and h2_tag.a:



                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù† Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
                  link_tag = h2_tag.find('a', {'class':'css-o171kl'})
                  job_link = link_tag.get('href') if link_tag else None

                company = container.find('a', {'class': 'css-ipsyv7'}).get_text(strip=True)
                location = container.find('span', {'class': 'css-16x61xq'}).get_text(strip=True)

                # 3. Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ Ø±Ø§Ø¨Ø·ØŒ Ù†Ø¯Ø®Ù„ ÙÙˆØ±Ø§Ù‹ Ù„Ø³Ø­Ø¨ Ø§Ù„Ø±Ø§ØªØ¨ ÙˆØ§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
                salary = "ØºÙŠØ± Ù…Ø¹Ù„Ù†"
                requirements = "Ù„Ø§ ÙŠÙˆØ¬Ø¯"

                if job_link:
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¯ÙˆÙ…ÙŠÙ† Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù†Ø³Ø¨ÙŠØ§Ù‹ (Relative URL)
                    full_link = job_link if job_link.startswith('http') else f"https://wuzzuf.net{job_link}"
                    logging.info(f"ğŸ” Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ø³Ø­Ø¨ ØªÙØ§ØµÙŠÙ„: {title}")
                    salary, requirements = self.get_internal_details(full_link)

                # Ø¥Ø¶Ø§ÙØ© ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù‚Ø§Ù…ÙˆØ³ ÙˆØ§Ø­Ø¯ ÙŠÙ…Ø«Ù„ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ¸ÙŠÙØ©
                page_results.append({
                    "Title": title,
                    "Company": company,
                    "Location": location,
                    "Salary": salary,
                    "Requirements": requirements,
                    "Link": job_link
                })

                # ØªØ£Ø®ÙŠØ± Ø¨Ø³ÙŠØ· Ø¬Ø¯Ø§Ù‹ Ø¨ÙŠÙ† Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„ÙƒÙ„ Ø±Ø§Ø¨Ø· ÙˆØ±Ø§Ø¨Ø· Ù„Ø¹Ø¯Ù… Ø§Ù„Ø­Ø¸Ø±
                time.sleep(1)

            except AttributeError:
                continue

        return page_results

    def get_internal_details(self, job_url):
        """Ø§Ù„Ø¯Ø®ÙˆÙ„ Ù„Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ Ù„Ø³Ø­Ø¨ Ø§Ù„Ø±Ø§ØªØ¨ ÙˆØ§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª"""
        inner_soup = self.get_soup(job_url)
        if not inner_soup:
            return "N/A", "N/A"

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±Ø§ØªØ¨
        salary_tag = inner_soup.find("span", {"class": "css-iu2m7n"})
        salary = salary_tag.get_text(strip=True) if salary_tag else "Confidential"

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
        req_container = inner_soup.find("div", {'class': 'css-1lqavbg'})
        requirements = req_container.get_text(strip=True) if req_container else "Requirements not listed"

        return salary, requirements

